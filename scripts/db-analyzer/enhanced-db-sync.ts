#!/usr/bin/env ts-node

import * as fs from 'fs/promises';
import * as path from 'path';
import {
  EnhancedSchemaAnalyzer,
  SchemaAnalysisResult,
} from './enhanced-schema-analyzer';
import {
  EnhancedEntityGenerator,
  EntityGenerationOptions,
} from './enhanced-entity-generator';
import {
  EnhancedRepositoryGenerator,
  RepositoryGenerationOptions,
} from './enhanced-repository-generator';
import {
  ProcedureExtractor,
  ProcedureExtractionOptions,
} from './procedure-extractor';

/**
 * ğŸš€ Enhanced Database Synchronization - DB ë™ê¸°í™” í†µí•© ê´€ë¦¬ì
 *
 * ğŸ“‹ í•µì‹¬ ê¸°ëŠ¥:
 * 1. DB ìŠ¤í‚¤ë§ˆ ë¶„ì„ - MySQL í…Œì´ë¸” êµ¬ì¡° ì‹¤ì‹œê°„ ë¶„ì„
 * 2. Entity ìë™ ìƒì„± - TypeORM Entity í´ë˜ìŠ¤ ìë™ ìƒì„± ë° ë³‘í•©
 * 3. Repository ìë™ ìƒì„± - ê¸°ë³¸ CRUD ë©”ì„œë“œ í¬í•¨ Repository ìƒì„±
 * 4. Procedure/Function SQL íŒŒì¼ ì¶”ì¶œ - ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ ê°œë³„ íŒŒì¼ ì¶”ì¶œ
 * 5. index.ts íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸ - ëª¨ë“  ìƒì„± íŒŒì¼ ìë™ export
 * 6. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡¤ë°± - ì•ˆì „í•œ ë°±ì—…/ë³µì› ì‹œìŠ¤í…œ
 *
 * ğŸ”„ ë™ì‘ ì›ë¦¬:
 * - MySQL INFORMATION_SCHEMAë¥¼ í†µí•œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
 * - snake_case â†’ camelCase ìë™ ë³€í™˜
 * - ê¸°ì¡´ ìˆ˜ë™ ì½”ë“œ ë³´ì¡´í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ë³‘í•©
 * - ì‚­ì œëœ í…Œì´ë¸” ìë™ ê°ì§€ ë° @deprecated ì²˜ë¦¬
 * - í™˜ê²½ë³„(dev/qa/prod) ì„¤ì • ì§€ì›
 */

interface DatabaseConfig {
  host: string;
  port: number;
  user: string;
  password: string;
  database: string;
}

interface SyncOptions {
  environment: string;
  outputBaseDir: string;
  backup: boolean;
  overwrite: boolean;
  skipEntities: boolean;
  skipRepositories: boolean;
  skipProcedures: boolean;
  generateComments: boolean;
  generateRelations: boolean;
  dryRun: boolean;
}

interface SyncResult {
  success: boolean;
  schemaResult?: SchemaAnalysisResult;
  generatedFiles: {
    entities: string[];
    repositories: string[];
    procedures: string[];
  };
  errors: string[];
  rollbackPerformed: boolean;
}

class EnhancedDbSync {
  private config: DatabaseConfig;
  private options: SyncOptions;
  private backupDir?: string;
  private generatedFiles: string[] = [];

  constructor(config: DatabaseConfig, options: SyncOptions) {
    this.config = config;
    this.options = options;
  }

  /**
   * ì „ì²´ ë™ê¸°í™” ì‹¤í–‰ - DB ìŠ¤í‚¤ë§ˆì™€ ì½”ë“œ ë™ê¸°í™” ë©”ì¸ í”„ë¡œì„¸ìŠ¤
   *
   * ğŸ”„ ì‹¤í–‰ ìˆœì„œ:
   * 1. ìŠ¤í‚¤ë§ˆ ë¶„ì„: MySQL DB êµ¬ì¡° ë¶„ì„
   * 2. ì‚­ì œëœ í…Œì´ë¸” ê°ì§€: ê¸°ì¡´ Entityì™€ ë¹„êµí•˜ì—¬ ì‚­ì œëœ í…Œì´ë¸” ì°¾ê¸°
   * 3. Entity ìƒì„±: TypeORM Entity í´ë˜ìŠ¤ ìƒì„±/ë³‘í•©
   * 4. Repository ìƒì„±: ê¸°ë³¸ CRUD Repository ìƒì„±
   * 5. Procedure ì¶”ì¶œ: ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ SQL íŒŒì¼ ì¶”ì¶œ
   * 6. ì½”ë“œ ê²€ì¦: TypeScript ì»´íŒŒì¼ ì²´í¬
   */
  async execute(): Promise<SyncResult> {
    const result: SyncResult = {
      success: false,
      generatedFiles: {
        entities: [],
        repositories: [],
        procedures: [],
      },
      errors: [],
      rollbackPerformed: false,
    };

    try {
      console.log(
        `ğŸš€ Starting Enhanced DB Sync for ${this.options.environment} environment`,
      );
      console.log(
        `ğŸ“Š Database: ${this.config.database}@${this.config.host}:${this.config.port}`,
      );

      // 1. ì „ì²´ ë°±ì—… ìƒì„± (ë¹„í™œì„±í™”)
      // if (this.options.backup) {
      //   await this.createFullBackup();
      // }

      // 2. ìŠ¤í‚¤ë§ˆ ë¶„ì„
      console.log('\nğŸ“‹ Step 1: Analyzing database schema...');
      const schemaResult = await this.analyzeSchema();
      result.schemaResult = schemaResult;

      // Dry runì¸ ê²½ìš° ë¶„ì„ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ
      if (this.options.dryRun) {
        await this.printDryRunResults(schemaResult);
        result.success = true;
        return result;
      }

      // 2.5. ì‚­ì œëœ í…Œì´ë¸” ê°ì§€ ë° Deprecate ì²˜ë¦¬
      console.log('\nğŸ—‘ï¸ Step 2: Checking for deleted tables...');
      await this.handleDeletedTables(schemaResult);

      // 3. Entity ìƒì„±
      if (!this.options.skipEntities) {
        console.log('\nğŸ—ï¸ Step 3: Generating entities...');
        const entityFiles = await this.generateEntities(schemaResult);
        result.generatedFiles.entities = entityFiles;
      }

      // 4. Repository ìƒì„±
      if (!this.options.skipRepositories) {
        console.log('\nğŸ”§ Step 4: Generating repositories...');
        const repositoryFiles = await this.generateRepositories(schemaResult);
        result.generatedFiles.repositories = repositoryFiles;

        // 4.5. Repository index.ts ì¬ìƒì„± (deprecated Repository ì œì™¸)
        console.log(
          '\nğŸ”„ Step 4.5: Updating repository index with deprecated exclusions...',
        );
        await this.updateRepositoryIndex(schemaResult);
      }

      // 5. Procedure/Function ì¶”ì¶œ
      if (!this.options.skipProcedures) {
        console.log('\nğŸª Step 4: Extracting procedures and functions...');
        const procedureFiles = await this.extractProcedures(schemaResult);
        result.generatedFiles.procedures = procedureFiles;
      }

      // 6. ê²€ì¦
      console.log('\nğŸ§ª Step 5: Validating generated code...');
      await this.validateGeneratedCode();

      // 7. ìµœì¢… ìš”ì•½ ìƒì„± (ë¹„í™œì„±í™”)
      // await this.generateSummaryReport(result);

      result.success = true;
      console.log('\nğŸ‰ Enhanced DB Sync completed successfully!');
    } catch (error) {
      console.error('\nğŸ’¥ Enhanced DB Sync failed:', error);
      result.errors.push(error.message);

      // ë¡¤ë°± ì‹¤í–‰ (ë¹„í™œì„±í™”)
      // if (this.options.backup && this.backupDir) {
      //   console.log('\nğŸ”„ Performing rollback...');
      //   await this.performRollback();
      //   result.rollbackPerformed = true;
      // }

      throw error;
    }

    return result;
  }

  /**
   * ì „ì²´ ë°±ì—… ìƒì„±
   */
  private async createFullBackup(): Promise<void> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    this.backupDir = path.join(
      this.options.outputBaseDir,
      `../.backup-full-${timestamp}`,
    );

    console.log(`ğŸ“¦ Creating full backup: ${this.backupDir}`);

    try {
      await fs.mkdir(this.backupDir, { recursive: true });

      // ë°±ì—…í•  ë””ë ‰í† ë¦¬ë“¤
      const dirsToBackup = [
        path.join(this.options.outputBaseDir, 'entities'),
        path.join(this.options.outputBaseDir, 'repositories'),
        path.join(this.options.outputBaseDir, 'procedures'),
      ];

      for (const dir of dirsToBackup) {
        const exists = await fs
          .access(dir)
          .then(() => true)
          .catch(() => false);
        if (exists) {
          const backupSubDir = path.join(this.backupDir, path.basename(dir));
          await this.copyDirectory(dir, backupSubDir);
        }
      }

      console.log('âœ… Full backup created successfully');
    } catch (error) {
      console.warn('âš ï¸ Failed to create full backup:', error);
    }
  }

  /**
   * ë””ë ‰í† ë¦¬ ë³µì‚¬
   */
  private async copyDirectory(src: string, dest: string): Promise<void> {
    const entries = await fs.readdir(src, { withFileTypes: true });

    await fs.mkdir(dest, { recursive: true });

    for (const entry of entries) {
      const srcPath = path.join(src, entry.name);
      const destPath = path.join(dest, entry.name);

      if (entry.isDirectory()) {
        await this.copyDirectory(srcPath, destPath);
      } else {
        await fs.copyFile(srcPath, destPath);
      }
    }
  }

  /**
   * ìŠ¤í‚¤ë§ˆ ë¶„ì„ - MySQL DB êµ¬ì¡° ì‹¤ì‹œê°„ ë¶„ì„
   *
   * ğŸ“Š ë¶„ì„ ëŒ€ìƒ:
   * - í…Œì´ë¸” êµ¬ì¡° (ì»¬ëŸ¼, íƒ€ì…, ì œì•½ì¡°ê±´)
   * - ì¸ë±ìŠ¤ ì •ë³´ (Primary Key, Unique, Index)
   * - ì™¸ë˜í‚¤ ê´€ê³„ (ì°¸ì¡° í…Œì´ë¸”, ì‚­ì œ/ì—…ë°ì´íŠ¸ ê·œì¹™)
   * - ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ (íŒŒë¼ë¯¸í„°, ë°˜í™˜ íƒ€ì…)
   *
   * ğŸ’¡ í•µì‹¬: INFORMATION_SCHEMA í…Œì´ë¸”ì„ í†µí•œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
   */
  private async analyzeSchema(): Promise<SchemaAnalysisResult> {
    const analyzer = new EnhancedSchemaAnalyzer(
      this.config,
      this.options.environment,
    );

    try {
      await analyzer.connect();
      const result = await analyzer.analyzeSchema();

      // ë¶„ì„ ê²°ê³¼ ì €ì¥ (ë¹„í™œì„±í™”)
      // const outputPath = path.join(
      //   this.options.outputBaseDir,
      //   `${this.options.environment}-schema.json`,
      // );
      // await analyzer.saveAnalysisResult(result, outputPath);

      return result;
    } finally {
      await analyzer.disconnect();
    }
  }

  /**
   * ì‚­ì œëœ í…Œì´ë¸” ê°ì§€ ë° Deprecate ì²˜ë¦¬ - ì•ˆì „í•œ í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥
   *
   * ğŸ” ê°ì§€ ë¡œì§:
   * 1. í˜„ì¬ DB í…Œì´ë¸” ëª©ë¡ ìˆ˜ì§‘
   * 2. ê¸°ì¡´ Entity íŒŒì¼ë“¤ê³¼ ë¹„êµ
   * 3. DBì—ì„œ ì‚­ì œëœ í…Œì´ë¸” ì‹ë³„
   *
   * ğŸ·ï¸ Deprecate ì²˜ë¦¬:
   * - Entity íŒŒì¼ì— @deprecated ì£¼ì„ ì¶”ê°€
   * - Repository íŒŒì¼ì— @deprecated ì£¼ì„ ì¶”ê°€
   * - index.tsì—ì„œ ALL_ENTITIES/ALL_REPOSITORIES ë°°ì—´ì—ì„œ ì œì™¸
   * - ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€ (íŒŒì¼ì€ ì‚­ì œí•˜ì§€ ì•ŠìŒ)
   */
  private async handleDeletedTables(
    schemaResult: SchemaAnalysisResult,
  ): Promise<void> {
    try {
      const entitiesDir = path.join(this.options.outputBaseDir, 'entities');
      const repositoriesDir = path.join(
        this.options.outputBaseDir,
        'repositories',
      );

      // í˜„ì¬ DBì— ìˆëŠ” í…Œì´ë¸” ì´ë¦„ë“¤
      const currentTables = new Set(
        schemaResult.tables.map((table) => table.tableName),
      );

      // ê¸°ì¡´ Entity íŒŒì¼ë“¤ í™•ì¸
      const existingEntityFiles =
        await this.getExistingEntityFiles(entitiesDir);
      const existingRepositoryFiles =
        await this.getExistingRepositoryFiles(repositoriesDir);

      // ì‚­ì œëœ í…Œì´ë¸”ë“¤ ì°¾ê¸°
      const deletedTables = new Set<string>();

      for (const entityFile of existingEntityFiles) {
        const tableName = this.extractTableNameFromEntityFile(entityFile);
        if (tableName && !currentTables.has(tableName)) {
          deletedTables.add(tableName);
        }
      }

      if (deletedTables.size > 0) {
        console.log(
          `   ğŸ—‘ï¸ Found ${deletedTables.size} deleted table(s): ${Array.from(deletedTables).join(', ')}`,
        );

        // Entity íŒŒì¼ë“¤ì— Deprecate ì£¼ì„ ì¶”ê°€
        for (const tableName of deletedTables) {
          await this.addDeprecateCommentToEntity(entitiesDir, tableName);
          await this.addDeprecateCommentToRepository(
            repositoriesDir,
            tableName,
          );
        }
      } else {
        console.log('   âœ… No deleted tables found');
      }
    } catch (error) {
      console.warn('   âš ï¸ Failed to check for deleted tables:', error.message);
    }
  }

  /**
   * ê¸°ì¡´ Entity íŒŒì¼ë“¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
   */
  private async getExistingEntityFiles(entitiesDir: string): Promise<string[]> {
    try {
      const files = await fs.readdir(entitiesDir);
      return files.filter(
        (file) => file.endsWith('.entity.ts') && file !== 'index.ts',
      );
    } catch {
      return [];
    }
  }

  /**
   * ê¸°ì¡´ Repository íŒŒì¼ë“¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
   */
  private async getExistingRepositoryFiles(
    repositoriesDir: string,
  ): Promise<string[]> {
    try {
      const files = await fs.readdir(repositoriesDir);
      return files.filter(
        (file) => file.endsWith('.repository.ts') && file !== 'index.ts',
      );
    } catch {
      return [];
    }
  }

  /**
   * Entity íŒŒì¼ëª…ì—ì„œ í…Œì´ë¸”ëª… ì¶”ì¶œ
   */
  private extractTableNameFromEntityFile(fileName: string): string | null {
    // tb-board.entity.ts -> tb_board
    const match = fileName.match(/^(.+)\.entity\.ts$/);
    if (match) {
      return match[1].replace(/-/g, '_');
    }
    return null;
  }

  /**
   * Entity íŒŒì¼ì— Deprecate ì£¼ì„ ì¶”ê°€
   */
  private async addDeprecateCommentToEntity(
    entitiesDir: string,
    tableName: string,
  ): Promise<void> {
    const fileName = `${tableName.replace(/_/g, '-')}.entity.ts`;
    const filePath = path.join(entitiesDir, fileName);

    try {
      const content = await fs.readFile(filePath, 'utf-8');

      // ì´ë¯¸ @deprecatedê°€ ìˆëŠ”ì§€ í™•ì¸
      if (content.includes('@deprecated')) {
        console.log(`   âš ï¸ ${fileName} already has @deprecated comment`);
        return;
      }

      // @Entity ë°ì½”ë ˆì´í„° ì•ì— deprecate ì£¼ì„ ì¶”ê°€
      const deprecateComment = `/**
 * @deprecated This table has been deleted from the database.
 * This entity is kept for backward compatibility but should not be used.
 * ì´ í…Œì´ë¸”ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.
 * ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
 * 
 * Deletion detected on: ${new Date().toISOString().split('T')[0]}
 */`;

      const updatedContent = content.replace(
        /(@Entity\([^)]+\))/,
        `${deprecateComment}\n$1`,
      );

      await fs.writeFile(filePath, updatedContent, 'utf-8');
      console.log(`   ğŸ·ï¸ Added @deprecated to ${fileName}`);
    } catch (error) {
      console.warn(
        `   âš ï¸ Failed to add @deprecated to ${fileName}:`,
        error.message,
      );
    }
  }

  /**
   * Repository íŒŒì¼ì— Deprecate ì£¼ì„ ì¶”ê°€
   */
  private async addDeprecateCommentToRepository(
    repositoriesDir: string,
    tableName: string,
  ): Promise<void> {
    const fileName = `${tableName.replace(/_/g, '-')}.repository.ts`;
    const filePath = path.join(repositoriesDir, fileName);

    try {
      const content = await fs.readFile(filePath, 'utf-8');

      // ì´ë¯¸ @deprecatedê°€ ìˆëŠ”ì§€ í™•ì¸
      if (content.includes('@deprecated')) {
        console.log(`   âš ï¸ ${fileName} already has @deprecated comment`);
        return;
      }

      // @Injectable ë°ì½”ë ˆì´í„° ì•ì— deprecate ì£¼ì„ ì¶”ê°€
      const deprecateComment = `/**
 * @deprecated This repository is for a deleted table.
 * This repository is kept for backward compatibility but should not be used.
 * ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ” ì‚­ì œëœ í…Œì´ë¸”ìš©ì…ë‹ˆë‹¤.
 * ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
 * 
 * Deletion detected on: ${new Date().toISOString().split('T')[0]}
 */`;

      const updatedContent = content.replace(
        /(@Injectable\(\))/,
        `${deprecateComment}\n$1`,
      );

      await fs.writeFile(filePath, updatedContent, 'utf-8');
      console.log(`   ğŸ·ï¸ Added @deprecated to ${fileName}`);
    } catch (error) {
      console.warn(
        `   âš ï¸ Failed to add @deprecated to ${fileName}:`,
        error.message,
      );
    }
  }

  /**
   * Entity ìƒì„± - TypeORM Entity í´ë˜ìŠ¤ ìë™ ìƒì„± ë° ìŠ¤ë§ˆíŠ¸ ë³‘í•©
   *
   * ğŸ—ï¸ ìƒì„± ê³¼ì •:
   * 1. í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ â†’ TypeORM Entity ë³€í™˜
   * 2. snake_case â†’ camelCase í”„ë¡œí¼í‹° ë³€í™˜
   * 3. ê¸°ì¡´ Entity íŒŒì¼ê³¼ ë³‘í•© (ìˆ˜ë™ ê´€ê³„ ë³´ì¡´)
   * 4. ê´€ê³„ ë§¤í•‘ ìë™ ìƒì„± (OneToMany, ManyToOne)
   * 5. ì¸ë±ìŠ¤ ë° ì œì•½ì¡°ê±´ ì ìš©
   *
   * ğŸ’¡ ìŠ¤ë§ˆíŠ¸ ë³‘í•©: ê¸°ì¡´ ìˆ˜ë™ ì½”ë“œ(ê´€ê³„, import) ë³´ì¡´
   */
  private async generateEntities(
    schemaResult: SchemaAnalysisResult,
  ): Promise<string[]> {
    const outputDir = path.join(this.options.outputBaseDir, 'entities');

    const options: EntityGenerationOptions = {
      outputDir,
      backup: false, // ì „ì²´ ë°±ì—…ì—ì„œ ì²˜ë¦¬ë¨
      overwrite: this.options.overwrite,
      includeComments: this.options.generateComments,
      generateRelations: this.options.generateRelations,
      useStrictTypes: true,
    };

    const generator = new EnhancedEntityGenerator(schemaResult, options);
    await generator.generateEntities();

    // ìƒì„±ëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜
    const files = await fs.readdir(outputDir);
    return files.filter(
      (file) => file.endsWith('.entity.ts') || file === 'index.ts',
    );
  }

  /**
   * Repository ìƒì„± - ê¸°ë³¸ CRUD ë©”ì„œë“œ í¬í•¨ Repository ìë™ ìƒì„±
   *
   * ğŸ”§ ìƒì„± ê·œì¹™:
   * 1. ê°™ì€ í…Œì´ë¸” ì²˜ë¦¬í•˜ëŠ” ê¸°ì¡´ Repository ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
   * 2. ìƒˆ í…Œì´ë¸”ì— ëŒ€í•´ì„œë§Œ Repository ìƒì„±
   * 3. ê¸°ë³¸ CRUD ë©”ì„œë“œ í…œí”Œë¦¿ í¬í•¨
   * 4. íƒ€ì… ì•ˆì „ì„± ë³´ì¥ (Generic Repository<Entity>)
   *
   * ğŸ“ ìƒì„± íŒŒì¼: {table-name}.repository.ts
   */
  private async generateRepositories(
    schemaResult: SchemaAnalysisResult,
  ): Promise<string[]> {
    const outputDir = path.join(this.options.outputBaseDir, 'repositories');

    const options: RepositoryGenerationOptions = {
      outputDir,
      backup: false, // ì „ì²´ ë°±ì—…ì—ì„œ ì²˜ë¦¬ë¨
      overwrite: this.options.overwrite,
      includeComments: false,
      generateBasicMethods: false,
      generateCustomMethods: false,
    };

    const generator = new EnhancedRepositoryGenerator(schemaResult, options);
    await generator.generateRepositories();

    // ìƒì„±ëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜
    const files = await fs.readdir(outputDir);
    return files.filter(
      (file) => file.endsWith('.repository.ts') || file === 'index.ts',
    );
  }

  /**
   * Repository index.ts ì—…ë°ì´íŠ¸ - ìë™ export ê´€ë¦¬ (deprecated ì œì™¸)
   *
   * ğŸ“¦ ì—…ë°ì´íŠ¸ ë‚´ìš©:
   * 1. ëª¨ë“  Repository íŒŒì¼ ìŠ¤ìº”
   * 2. @deprecated ì£¼ì„ ìˆëŠ” Repository ì‹ë³„
   * 3. export ë¬¸ì€ ëª¨ë‘ í¬í•¨ (í•˜ìœ„ í˜¸í™˜ì„±)
   * 4. ALL_REPOSITORIES ë°°ì—´ì—ëŠ” deprecated ì œì™¸
   *
   * ğŸ’¡ ëª©ì : ìë™í™”ëœ ëª¨ë“ˆ ê´€ë¦¬ ë° ì•ˆì „í•œ deprecated ì²˜ë¦¬
   */
  private async updateRepositoryIndex(
    schemaResult: SchemaAnalysisResult,
  ): Promise<void> {
    const repositoriesDir = path.join(
      this.options.outputBaseDir,
      'repositories',
    );
    const indexPath = path.join(repositoriesDir, 'index.ts');

    try {
      // ê¸°ì¡´ íŒŒì¼ë“¤ ìŠ¤ìº”
      const files = await fs.readdir(repositoriesDir);
      const repositoryFiles = files.filter(
        (file) => file.endsWith('.repository.ts') && file !== 'index.ts',
      );

      const existingExports: string[] = [];
      const existingImports: string[] = [];
      const repositoryNames: string[] = [];

      for (const file of repositoryFiles) {
        const filePath = path.join(repositoriesDir, file);

        try {
          // íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ì„œ Repository í´ë˜ìŠ¤ëª… ì¶”ì¶œ
          const content = await fs.readFile(filePath, 'utf-8');
          const classMatch = content.match(/export class (\w+Repository)/);

          if (classMatch) {
            const repositoryName = classMatch[1];
            const exportName = file.replace('.repository.ts', '');

            // ëª¨ë“  RepositoryëŠ” exportí•˜ì§€ë§Œ, deprecatedê°€ ì•„ë‹Œ ê²ƒë§Œ ALL_REPOSITORIESì— í¬í•¨
            existingExports.push(`export * from './${exportName}.repository';`);

            const isDeprecated = content.includes('@deprecated');
            if (!isDeprecated) {
              repositoryNames.push(repositoryName);
              existingImports.push(
                `import { ${repositoryName} } from './${exportName}.repository';`,
              );
            }
          }
        } catch (error) {
          console.warn(`âš ï¸ Failed to process ${file}:`, error.message);
          continue;
        }
      }

      const exports = existingExports.sort();
      const imports = existingImports.join('\n');
      const sortedRepositoryNames = repositoryNames.sort();

      const content = `// ğŸ¤– Auto-generated repository exports
// Environment: ${schemaResult.database.environment}
// Tables: ${schemaResult.tables.length}

${exports.join('\n')}

// ğŸš€ ìë™í™”ë¥¼ ìœ„í•œ Repository ë°°ì—´ export
${imports}

/**
 * ëª¨ë“  Repository ë°°ì—´ - ìë™ ìƒì„±ë¨
 * ìƒˆ Repositoryê°€ DBì— ì¶”ê°€ë˜ë©´ ìë™ìœ¼ë¡œ ì—¬ê¸°ì— í¬í•¨ë©ë‹ˆë‹¤.
 * 
 * Note: Deprecated repositories (deleted tables) are exported but not included in ALL_REPOSITORIES
 */
export const ALL_REPOSITORIES = [
${sortedRepositoryNames.map((name) => `  ${name},`).join('\n')}
];
`;

      // ê¸°ì¡´ íŒŒì¼ê³¼ ë‚´ìš©ì´ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
      let shouldUpdate = true;
      try {
        const existingContent = await fs.readFile(indexPath, 'utf-8');
        shouldUpdate = existingContent !== content;
      } catch {
        // íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        shouldUpdate = true;
      }

      if (shouldUpdate) {
        await fs.writeFile(indexPath, content, 'utf-8');
        console.log(
          '   ğŸ“ Updated repositories index.ts with deprecated exclusions',
        );
      } else {
        console.log('   âœ… Repository index.ts is already up to date');
      }
    } catch (error) {
      console.warn('   âš ï¸ Failed to update repository index:', error.message);
    }
  }

  /**
   * Procedure/Function ì¶”ì¶œ - ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ ê°œë³„ SQL íŒŒì¼ ì¶”ì¶œ
   *
   * ğŸª ì¶”ì¶œ ê³¼ì •:
   * 1. DBì—ì„œ ì €ì¥ í”„ë¡œì‹œì €/í•¨ìˆ˜ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
   * 2. ê°ê°ì„ ê°œë³„ .sql íŒŒì¼ë¡œ ì¶”ì¶œ
   * 3. íŒŒë¼ë¯¸í„° ì •ë³´ ë° ì£¼ì„ í¬í•¨
   * 4. procedures/ ë° functions/ ë””ë ‰í† ë¦¬ ë¶„ë¦¬
   *
   * ğŸ“ íŒŒì¼ êµ¬ì¡°: {procedure_name}.sql, {function_name}.sql
   * ğŸ’¡ í™œìš©: ê°œë³„ import ê°€ëŠ¥, ë²„ì „ ê´€ë¦¬ ìš©ì´
   */
  private async extractProcedures(
    schemaResult: SchemaAnalysisResult,
  ): Promise<string[]> {
    const outputDir = path.join(this.options.outputBaseDir, 'procedures');

    const options: ProcedureExtractionOptions = {
      outputDir,
      backup: false, // ì „ì²´ ë°±ì—…ì—ì„œ ì²˜ë¦¬ë¨
      overwrite: this.options.overwrite,
      includeComments: this.options.generateComments,
      separateByType: true,
      generateDocumentation: true,
    };

    const extractor = new ProcedureExtractor(schemaResult, options);
    await extractor.extractProcedures();

    // ìƒì„±ëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜ (ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ ì°¾ê¸°)
    const files: string[] = [];
    await this.collectFiles(outputDir, files);
    return files.map((file) => path.relative(outputDir, file));
  }

  /**
   * íŒŒì¼ ìˆ˜ì§‘ (ì¬ê·€)
   */
  private async collectFiles(dir: string, files: string[]): Promise<void> {
    const entries = await fs.readdir(dir, { withFileTypes: true });

    for (const entry of entries) {
      const fullPath = path.join(dir, entry.name);
      if (entry.isDirectory()) {
        await this.collectFiles(fullPath, files);
      } else {
        files.push(fullPath);
      }
    }
  }

  /**
   * ìƒì„±ëœ ì½”ë“œ ê²€ì¦ - TypeScript ì»´íŒŒì¼ ì²´í¬ë¡œ ì½”ë“œ í’ˆì§ˆ ë³´ì¥
   *
   * ğŸ§ª ê²€ì¦ í•­ëª©:
   * 1. TypeScript ì»´íŒŒì¼ ì—ëŸ¬ ì²´í¬
   * 2. Entity ê´€ê³„ ë§¤í•‘ ìœ íš¨ì„±
   * 3. Import ë¬¸ ì •í™•ì„±
   * 4. íƒ€ì… ì•ˆì „ì„± í™•ì¸
   *
   * âš ï¸ ì‹¤íŒ¨ ì‹œ: ê²½ê³  ì¶œë ¥í•˜ì§€ë§Œ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
   */
  private async validateGeneratedCode(): Promise<void> {
    try {
      // TypeScript ì»´íŒŒì¼ ì²´í¬
      const { spawn } = require('child_process');

      await new Promise((resolve, reject) => {
        const tsc = spawn(
          'npx',
          ['tsc', '--noEmit', '--project', 'libs/database/tsconfig.lib.json'],
          {
            stdio: 'pipe',
          },
        );

        let output = '';
        tsc.stdout.on('data', (data: Buffer) => {
          output += data.toString();
        });

        tsc.stderr.on('data', (data: Buffer) => {
          output += data.toString();
        });

        tsc.on('close', (code: number) => {
          if (code === 0) {
            console.log('âœ… TypeScript compilation check passed');
            resolve(void 0);
          } else {
            console.error('âŒ TypeScript compilation errors:');
            console.error(output);
            reject(new Error('TypeScript compilation failed'));
          }
        });
      });
    } catch (error) {
      console.warn('âš ï¸ Code validation failed:', error.message);
      // ê²€ì¦ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
    }
  }

  /**
   * Dry run ê²°ê³¼ ì¶œë ¥
   */
  private async printDryRunResults(
    schemaResult: SchemaAnalysisResult,
  ): Promise<void> {
    console.log('\nğŸ“Š DRY RUN RESULTS');
    console.log('==================');
    console.log(`Environment: ${this.options.environment}`);
    console.log(`Database: ${schemaResult.database.database}`);
    console.log(`Version: ${schemaResult.database.version}`);
    console.log(`Analyzed at: ${schemaResult.database.analyzedAt}`);
    console.log('');

    console.log('ğŸ“‹ Tables to process:');
    schemaResult.tables.forEach((table, index) => {
      console.log(
        `  ${index + 1}. ${table.tableName} (${table.columns.length} columns)`,
      );
    });

    console.log('\nğŸ”§ Procedures to extract:');
    schemaResult.procedures.forEach((proc, index) => {
      console.log(
        `  ${index + 1}. ${proc.name} (${proc.parameters.length} params)`,
      );
    });

    console.log('\nâš™ï¸ Functions to extract:');
    schemaResult.functions.forEach((func, index) => {
      console.log(
        `  ${index + 1}. ${func.name} (${func.parameters.length} params)`,
      );
    });

    console.log('\nğŸ“ Files that would be generated:');
    if (!this.options.skipEntities) {
      console.log('  Entities:');
      schemaResult.tables.forEach((table) => {
        console.log(`    - ${this.toKebabCase(table.tableName)}.entity.ts`);
      });
      console.log('    - index.ts');
    }

    if (!this.options.skipRepositories) {
      console.log('  Repositories:');
      schemaResult.tables.forEach((table) => {
        console.log(`    - ${this.toKebabCase(table.tableName)}.repository.ts`);
      });
      console.log('    - index.ts');
    }

    if (!this.options.skipProcedures) {
      console.log('  Procedures:');
      schemaResult.procedures.forEach((proc) => {
        console.log(`    - procedures/${proc.name.toLowerCase()}.sql`);
      });
      schemaResult.functions.forEach((func) => {
        console.log(`    - functions/${func.name.toLowerCase()}.sql`);
      });
      console.log('    - docs/index.md');
      console.log('    - docs/procedures.md');
      console.log('    - docs/functions.md');
      console.log('    - README.md');
    }
  }

  /**
   * ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
   */
  private async generateSummaryReport(result: SyncResult): Promise<void> {
    const reportPath = path.join(
      this.options.outputBaseDir,
      'sync-report.json',
    );

    const report = {
      timestamp: new Date().toISOString(),
      environment: this.options.environment,
      database: result.schemaResult?.database,
      options: this.options,
      results: {
        success: result.success,
        entitiesGenerated: result.generatedFiles.entities.length,
        repositoriesGenerated: result.generatedFiles.repositories.length,
        proceduresExtracted: result.generatedFiles.procedures.length,
        totalFiles: Object.values(result.generatedFiles).flat().length,
      },
      generatedFiles: result.generatedFiles,
      errors: result.errors,
      rollbackPerformed: result.rollbackPerformed,
    };

    await fs.writeFile(reportPath, JSON.stringify(report, null, 2), 'utf-8');
    console.log(`ğŸ“Š Sync report saved: ${reportPath}`);
  }

  /**
   * ë¡¤ë°± ì‹¤í–‰
   */
  private async performRollback(): Promise<void> {
    if (!this.backupDir) return;

    try {
      const dirsToRestore = ['entities', 'repositories', 'procedures'];

      for (const dir of dirsToRestore) {
        const backupPath = path.join(this.backupDir, dir);
        const targetPath = path.join(this.options.outputBaseDir, dir);

        const exists = await fs
          .access(backupPath)
          .then(() => true)
          .catch(() => false);
        if (exists) {
          // í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚­ì œ
          await fs.rm(targetPath, { recursive: true, force: true });

          // ë°±ì—…ì—ì„œ ë³µì›
          await this.copyDirectory(backupPath, targetPath);
          console.log(`âœ… Restored ${dir} from backup`);
        }
      }

      // ë°±ì—… ë””ë ‰í† ë¦¬ ì •ë¦¬
      await fs.rm(this.backupDir, { recursive: true, force: true });
      console.log('ğŸ§¹ Backup directory cleaned up');
    } catch (error) {
      console.error('âŒ Rollback failed:', error);
    }
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
  private toKebabCase(str: string): string {
    return str
      .replace(/([a-z])([A-Z])/g, '$1-$2')
      .toLowerCase()
      .replace(/_/g, '-');
  }
}

/**
 * CLI ì‹¤í–‰ í•¨ìˆ˜
 */
async function main() {
  const environment = process.argv[2] || process.env.NODE_ENV || 'dev';
  const outputBaseDirArg = process.argv[3] || 'libs/database/src';

  // ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
  const projectRoot = path.resolve(__dirname, '../..');
  const outputBaseDir = path.resolve(projectRoot, outputBaseDirArg);

  console.log(`ğŸš€ Enhanced Database Sync`);
  console.log(`Environment: ${environment}`);
  console.log(`Output: ${outputBaseDir}`);

  // í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì„¤ì • ì½ê¸°
  const config: DatabaseConfig = {
    host: process.env.DB_HOST || 'localhost',
    port: parseInt(process.env.DB_PORT || '3306'),
    user: process.env.DB_USER || 'root',
    password: process.env.DB_PASSWORD || '',
    database: process.env.DB_NAME || 'test',
  };

  // CLI ì˜µì…˜ íŒŒì‹±
  const options: SyncOptions = {
    environment,
    outputBaseDir,
    backup: !process.argv.includes('--no-backup'),
    overwrite: process.argv.includes('--overwrite'),
    skipEntities: process.argv.includes('--skip-entities'),
    skipRepositories: process.argv.includes('--skip-repositories'),
    skipProcedures: process.argv.includes('--skip-procedures'),
    generateComments: !process.argv.includes('--no-comments'),
    generateRelations: !process.argv.includes('--no-relations'),
    dryRun: process.argv.includes('--dry-run'),
  };

  const sync = new EnhancedDbSync(config, options);

  try {
    const result = await sync.execute();

    if (result.success) {
      console.log('\nğŸ‰ Database synchronization completed successfully!');
      process.exit(0);
    } else {
      console.error('\nğŸ’¥ Database synchronization failed');
      process.exit(1);
    }
  } catch (error) {
    console.error('\nğŸ’¥ Fatal error:', error);
    process.exit(1);
  }
}

// CLIì—ì„œ ì§ì ‘ ì‹¤í–‰ë˜ëŠ” ê²½ìš°
if (require.main === module) {
  main().catch(console.error);
}

export { EnhancedDbSync, SyncOptions, SyncResult };
